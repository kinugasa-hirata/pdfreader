import streamlit as st
import pandas as pd
import re
import PyPDF2
import io
from typing import Dict, List, Any
import numpy as np
import datetime
import base64

# Set page config - MUST be first Streamlit command
st.set_page_config(
    page_title="CMM ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒ¼ã‚µãƒ¼",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

def ensure_japanese_text(text):
    """Ensure text is properly encoded for Japanese characters"""
    if isinstance(text, str):
        try:
            # Test if text can be encoded/decoded properly
            text.encode('utf-8').decode('utf-8')
            return text
        except UnicodeError:
            # If there's an encoding issue, try to fix it
            return text.encode('utf-8', errors='replace').decode('utf-8')
    return str(text)

def convert_df_to_csv(df, encoding='utf-8-sig'):
    """Convert DataFrame to CSV string with proper Japanese encoding"""
    try:
        # Try the specified encoding first
        csv_string = df.to_csv(index=False, encoding=encoding, errors='replace')
        return csv_string
    except UnicodeEncodeError:
        try:
            # Fallback to UTF-8 without BOM
            csv_string = df.to_csv(index=False, encoding='utf-8', errors='replace')
            return csv_string
        except:
            # Final fallback to Shift-JIS for Japanese systems
            csv_string = df.to_csv(index=False, encoding='shift_jis', errors='replace')
            return csv_string

class CMMDataParser:
    def __init__(self):
        self.measurement_data = []
        self.coordinate_system_data = {}
        self.reference_elements = {}
        
    def convert_to_absolute(self, value):
        """Convert numerical value to absolute value"""
        try:
            if isinstance(value, (int, float)):
                return abs(value)
            elif isinstance(value, str):
                try:
                    num_value = float(value)
                    return abs(num_value)
                except ValueError:
                    return value
            else:
                return value
        except:
            return value
        
    def extract_pdf_text(self, file_content):
        """Extract text from PDF file with proper Japanese encoding"""
        try:
            pdf_file = io.BytesIO(file_content)
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            
            text = ""
            for page in pdf_reader.pages:
                page_text = page.extract_text()
                # Ensure Japanese text is properly handled
                if page_text:
                    page_text = ensure_japanese_text(page_text)
                    text += page_text + "\n"
            
            return text
        except Exception as e:
            st.error(f"PDFãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def parse_measurement_line(self, line):
        """Parse a single measurement line to extract values"""
        patterns = {
            'circle': r'(å††\d+|åŸºæº–å††\d+)\s+å††\(æœ€å°äºŒä¹—æ³•\)\s+ç‚¹æ•°\s+\((\d+)\)\s+(å†…å´|å¤–å´)?',
            'plane': r'(å¹³é¢\d+|.*å¹³é¢)\s+å¹³é¢\(æœ€å°äºŒä¹—æ³•\)\s+ç‚¹æ•°\s+\((\d+)\)',
            'line': r'(.*ç·š)\s+ç›´ç·š\(æœ€å°äºŒä¹—æ³•\)\s+ç‚¹æ•°\s+\((\d+)\)',
            'coordinate_value': r'([XYZ]-å€¤_.*?|[XYZ])\s+([XYZ])\s+([-\d.]+)\s+([-\d.]+)\s+([-\d.]+)\s+([-\d.]+)\s+([-\d.]+)',
            'diameter': r'D\s+([\d.]+)\s+([\d.]+)',
            'statistics': r'S=\s+([\d.]+)\s+Min=\([^)]+\)\s+([-\d.]+)\s+Max=\([^)]+\)\s+([-\d.]+)\s+å½¢çŠ¶=\s+([\d.]+)'
        }
        
        result = {}
        
        for pattern_name, pattern in patterns.items():
            match = re.search(pattern, line)
            if match:
                result['type'] = pattern_name
                result['match'] = match
                break
                
        return result if result else None
    
    def parse_cmm_data(self, text):
        """Parse the entire CMM measurement text"""
        lines = text.split('\n')
        current_element = None
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
            
            parsed_line = self.parse_measurement_line(line)
            
            if parsed_line:
                if parsed_line['type'] in ['circle', 'plane', 'line']:
                    if current_element:
                        self.measurement_data.append(current_element)
                    
                    current_element = {
                        'name': parsed_line['match'].group(1),
                        'type': parsed_line['type'],
                        'point_count': int(parsed_line['match'].group(2)) if len(parsed_line['match'].groups()) >= 2 else None,
                        'side': parsed_line['match'].group(3) if len(parsed_line['match'].groups()) >= 3 else None,
                        'coordinates': {},
                        'statistics': {},
                        'tolerances': {}
                    }
                
                elif parsed_line['type'] == 'coordinate_value' and current_element:
                    match = parsed_line['match']
                    coord_name = match.group(1)
                    coord_axis = match.group(2)
                    measured_value = self.convert_to_absolute(float(match.group(3)))
                    reference_value = self.convert_to_absolute(float(match.group(4)))
                    upper_tolerance = self.convert_to_absolute(float(match.group(5)))
                    lower_tolerance = self.convert_to_absolute(float(match.group(6)))
                    deviation = self.convert_to_absolute(float(match.group(7)))
                    
                    current_element['coordinates'][coord_name] = {
                        'axis': coord_axis,
                        'measured': measured_value,
                        'reference': reference_value,
                        'upper_tol': upper_tolerance,
                        'lower_tol': lower_tolerance,
                        'deviation': deviation
                    }
                
                elif parsed_line['type'] == 'diameter' and current_element:
                    match = parsed_line['match']
                    current_element['diameter'] = {
                        'measured': self.convert_to_absolute(float(match.group(1))),
                        'reference': self.convert_to_absolute(float(match.group(2)))
                    }
                
                elif parsed_line['type'] == 'statistics' and current_element:
                    match = parsed_line['match']
                    current_element['statistics'] = {
                        'std_dev': self.convert_to_absolute(float(match.group(1))),
                        'min_value': self.convert_to_absolute(float(match.group(2))),
                        'max_value': self.convert_to_absolute(float(match.group(3))),
                        'form_error': self.convert_to_absolute(float(match.group(4)))
                    }
            
            if 'åŸºæœ¬åº§æ¨™ç³»' in line:
                self.coordinate_system_data['name'] = line
                for j in range(i+1, min(i+10, len(lines))):
                    datum_line = lines[j].strip()
                    if 'ï¾ƒï¾ï½°ï¾€ï¾‘' in datum_line:
                        if 'datums' not in self.coordinate_system_data:
                            self.coordinate_system_data['datums'] = []
                        self.coordinate_system_data['datums'].append(datum_line)
        
        if current_element:
            self.measurement_data.append(current_element)
    
    def create_detailed_dataframe(self):
        """Create a detailed pandas DataFrame with all measurement data"""
        detailed_data = []
        
        for element in self.measurement_data:
            # Ensure Japanese text is properly encoded
            element_name = ensure_japanese_text(element['name'])
            element_type = ensure_japanese_text(element['type'])
            element_side = ensure_japanese_text(element.get('side', 'N/A'))
            
            base_info = {
                'è¦ç´ å': element_name,
                'ã‚¿ã‚¤ãƒ—': element_type,
                'ç‚¹æ•°': element.get('point_count', 'N/A'),
                'å´é¢': element_side
            }
            
            if 'statistics' in element:
                base_info.update({
                    'æ¨™æº–åå·®': element['statistics'].get('std_dev'),
                    'æœ€å°å€¤': element['statistics'].get('min_value'),
                    'æœ€å¤§å€¤': element['statistics'].get('max_value'),
                    'å½¢çŠ¶èª¤å·®': element['statistics'].get('form_error')
                })
            
            if 'diameter' in element:
                base_info.update({
                    'ç›´å¾„_å®Ÿæ¸¬å€¤': element['diameter']['measured'],
                    'ç›´å¾„_åŸºæº–å€¤': element['diameter']['reference'],
                    'ç›´å¾„_åå·®': self.convert_to_absolute(element['diameter']['measured'] - element['diameter']['reference'])
                })
            
            if element.get('coordinates'):
                for coord_name, coord_data in element['coordinates'].items():
                    row = base_info.copy()
                    within_tolerance = coord_data['lower_tol'] <= coord_data['deviation'] <= coord_data['upper_tol']
                    
                    # Ensure coordinate name and axis are properly encoded
                    coord_name_clean = ensure_japanese_text(coord_name)
                    coord_axis_clean = ensure_japanese_text(coord_data['axis'])
                    
                    row.update({
                        'åº§æ¨™å': coord_name_clean,
                        'è»¸': coord_axis_clean,
                        'å®Ÿæ¸¬å€¤': coord_data['measured'],
                        'åŸºæº–å€¤': coord_data['reference'],
                        'ä¸Šé™å…¬å·®': coord_data['upper_tol'],
                        'ä¸‹é™å…¬å·®': coord_data['lower_tol'],
                        'åå·®': coord_data['deviation'],
                        'å…¬å·®å†…': 'OK' if within_tolerance else 'NG'
                    })
                    detailed_data.append(row)
            else:
                detailed_data.append(base_info)
        
        return pd.DataFrame(detailed_data)

# Title and description - Preserving your custom title
st.markdown("# Zeissç¤¾æ¸¬å®šãƒ¬ãƒãƒ¼ãƒˆè§£æã‚¢ãƒ—ãƒª\nsponsored by æ ªå¼ä¼šç¤¾å¹³ç”°å•†åº—")
st.markdown("**Carl Zeiss CALYPSO ãƒ¬ãƒãƒ¼ãƒˆè§£æå™¨**")

# Sidebar - Preserving your simplified sidebar
with st.sidebar:
    st.header("ä½¿ã„æ–¹")
    st.markdown("1. PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    st.markdown("2. ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’è§£æå‡¦ç†")
    st.markdown("3. CSVãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    
    st.header("ğŸ“Š æ©Ÿèƒ½")
    st.markdown("- è©³ç´°è§£æãƒ‡ãƒ¼ã‚¿")
    st.markdown("- çµ¶å¯¾å€¤å¤‰æ›æ¸ˆã¿")
    st.markdown("- æ—¥æœ¬èªå¯¾å¿œã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°")

# File upload
st.header("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_file = st.file_uploader(
    "PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
    type="pdf",
    help="Carl Zeiss CALYPSO æ¸¬å®šãƒ¬ãƒãƒ¼ãƒˆï¼ˆPDFå½¢å¼ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
)

if uploaded_file is not None:
    # Show file details
    st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {uploaded_file.name}")
    st.info(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {uploaded_file.size} ãƒã‚¤ãƒˆ")
    
    # Process button
    if st.button("ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹", type="primary"):
        with st.spinner("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­..."):
            # Initialize parser
            parser = CMMDataParser()
            
            # Extract text
            file_content = uploaded_file.read()
            text = parser.extract_pdf_text(file_content)
            
            if text:
                # Parse data
                parser.parse_cmm_data(text)
                
                # Store in session state
                st.session_state.parser = parser
                st.session_state.processed = True
                
                st.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
            else:
                st.error("âŒ PDFã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")

# Display results if processed
if hasattr(st.session_state, 'processed') and st.session_state.processed:
    parser = st.session_state.parser
    
    # Data table - Only detailed view
    st.header("ğŸ“‹ æ¸¬å®šãƒ‡ãƒ¼ã‚¿ï¼ˆè©³ç´°ï¼‰")
    
    st.subheader("è©³ç´°è§£æãƒ‡ãƒ¼ã‚¿")
    detailed_df = parser.create_detailed_dataframe()
    
    # Show data info
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ãƒ‡ãƒ¼ã‚¿è¡Œæ•°", len(detailed_df))
    with col2:
        st.metric("ãƒ‡ãƒ¼ã‚¿åˆ—æ•°", len(detailed_df.columns))
    with col3:
        ok_count = len(detailed_df[detailed_df.get('å…¬å·®å†…', 'N/A') == 'OK']) if 'å…¬å·®å†…' in detailed_df.columns else 0
        st.metric("å…¬å·®å†…ãƒ‡ãƒ¼ã‚¿", ok_count)
    
    # Display the dataframe
    st.dataframe(detailed_df, use_container_width=True)
    
    # Generate timestamp for filenames
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Multiple download options for Japanese encoding
    st.subheader("ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # UTF-8 with BOM (Excel compatible)
        try:
            csv_utf8_bom = convert_df_to_csv(detailed_df, 'utf-8-sig')
            st.download_button(
                label="ğŸ“¥ Excelæ¨å¥¨ (UTF-8 BOM)",
                data=csv_utf8_bom,
                file_name=f"CMMè©³ç´°ãƒ‡ãƒ¼ã‚¿_Excel_{timestamp}.csv",
                mime="text/csv",
                type="primary",
                help="Microsoft Excel ã§æ—¥æœ¬èªã‚’æ­£ã—ãè¡¨ç¤º"
            )
        except Exception as e:
            st.error(f"UTF-8 BOM ã‚¨ãƒ©ãƒ¼: {e}")
    
    with col2:
        # UTF-8 without BOM
        try:
            csv_utf8 = convert_df_to_csv(detailed_df, 'utf-8')
            st.download_button(
                label="ğŸ“¥ æ¨™æº– (UTF-8)",
                data=csv_utf8,
                file_name=f"CMMè©³ç´°ãƒ‡ãƒ¼ã‚¿_æ¨™æº–_{timestamp}.csv",
                mime="text/csv",
                help="Google Sheets, LibreOffice å‘ã‘"
            )
        except Exception as e:
            st.error(f"UTF-8 ã‚¨ãƒ©ãƒ¼: {e}")
    
    with col3:
        # Shift-JIS for Japanese systems
        try:
            csv_sjis = convert_df_to_csv(detailed_df, 'shift_jis')
            st.download_button(
                label="ğŸ“¥ æ—¥æœ¬èªã‚·ã‚¹ãƒ†ãƒ  (Shift-JIS)",
                data=csv_sjis,
                file_name=f"CMMè©³ç´°ãƒ‡ãƒ¼ã‚¿_æ—¥æœ¬èª_{timestamp}.csv",
                mime="text/csv",
                help="æ—¥æœ¬èªã‚·ã‚¹ãƒ†ãƒ å‘ã‘"
            )
        except Exception as e:
            st.warning("Shift-JIS ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    # Encoding help section
    with st.expander("â“ ã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ"):
        st.markdown("""
        **æ¨å¥¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:**
        
        - **ğŸ“Š Microsoft Excel ã‚’ä½¿ç”¨** â†’ Excelæ¨å¥¨ (UTF-8 BOM)
        - **ğŸ“ˆ Google Sheets ã‚’ä½¿ç”¨** â†’ æ¨™æº– (UTF-8)  
        - **ğŸ‡¯ğŸ‡µ å¤ã„æ—¥æœ¬èªã‚·ã‚¹ãƒ†ãƒ ** â†’ æ—¥æœ¬èªã‚·ã‚¹ãƒ†ãƒ  (Shift-JIS)
        
        **æ–‡å­—åŒ–ã‘ã™ã‚‹å ´åˆ:**
        1. ç•°ãªã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©¦ã—ã¦ãã ã•ã„
        2. Excel ã®å ´åˆï¼šãƒ‡ãƒ¼ã‚¿ > ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ > ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é¸æŠ
        3. ãƒ¡ãƒ¢å¸³ã§é–‹ã„ã¦æ—¥æœ¬èªãŒæ­£ã—ãè¡¨ç¤ºã•ã‚Œã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„
        """)
    
    # Show data preview
    with st.expander("ğŸ“„ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®10è¡Œï¼‰"):
        st.dataframe(detailed_df.head(10))